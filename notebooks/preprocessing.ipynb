{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT\n",
    "* remove_null\n",
    "* lower case\n",
    "* stem and lemmatize\n",
    "\n",
    "## IMAGE\n",
    "* resize all and save (grayscale)\n",
    "* augmentation using GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sameep/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2023-03-16 15:50:22.752055: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 15:50:23.120580: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-16 15:50:23.128294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 15:50:23.128344: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-16 15:50:24.722791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 15:50:24.722974: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 15:50:24.722994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import cv2\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16395</td>\n",
       "      <td>handjob sold seper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37405</td>\n",
       "      <td>introduc fidget spinner for woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94180</td>\n",
       "      <td>happi pride month let' go beat up lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54321</td>\n",
       "      <td>laugh in [major of u. crime rate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97015</td>\n",
       "      <td>find out those 72 virgins.. are goat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                       text\n",
       "0  16395                         handjob sold seper\n",
       "1  37405          introduc fidget spinner for woman\n",
       "2  94180  happi pride month let' go beat up lesbian\n",
       "3  54321          laugh in [major of u. crime rate]\n",
       "4  97015       find out those 72 virgins.. are goat"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/facebook/train.csv')\n",
    "train_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "test_df = pd.read_csv('../data/facebook/test.csv')\n",
    "test_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "val_df = pd.read_csv('../data/facebook/val.csv')\n",
    "val_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Preprocessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    \n",
    "    def lower_case(self):\n",
    "        self.df['text'] = self.df['text'].apply(str.lower)\n",
    "\n",
    "    def remove_null(self):\n",
    "        for col in self.df.columns:\n",
    "            if(self.df[col].isnull().sum() > 0):\n",
    "                self.df.dropna(inplace = True)\n",
    "\n",
    "    def stem_and_lemmatize(self):\n",
    "        cleaned_text = []\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        for index in tqdm(range(self.df.shape[0])):\n",
    "            text = self.df['text'].iloc[index]\n",
    "\n",
    "            word_tokens = text.split()\n",
    "\n",
    "            for count, word in enumerate(word_tokens):\n",
    "                temp = lemmatizer.lemmatize(word)\n",
    "                word_tokens[count] = ps.stem(temp)\n",
    "\n",
    "            filtered_sentence = \" \".join(word_tokens).strip()\n",
    "            cleaned_text.append(filtered_sentence)\n",
    "        \n",
    "        self.df['text'] = np.array(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8500/8500 [00:08<00:00, 1056.69it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1836.59it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1564.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>it their charact not their color that matter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>don't be afraid to love again everyon is not l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>put bow on your pet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>i love everyth and everybody! except for squir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>everybodi love chocol chip cookies, even hitler</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label\n",
       "0  42953       it their charact not their color that matter      0\n",
       "1  23058  don't be afraid to love again everyon is not l...      0\n",
       "2  13894                                put bow on your pet      0\n",
       "3  37408  i love everyth and everybody! except for squir...      0\n",
       "4  82403    everybodi love chocol chip cookies, even hitler      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_preprocessor = Text_Preprocessor(train_df)\n",
    "train_text_preprocessor.lower_case()\n",
    "train_text_preprocessor.remove_null()\n",
    "train_text_preprocessor.stem_and_lemmatize()\n",
    "train_df = train_text_preprocessor.get_df()\n",
    "\n",
    "test_text_preprocessor = Text_Preprocessor(test_df)\n",
    "test_text_preprocessor.lower_case()\n",
    "test_text_preprocessor.remove_null()\n",
    "test_text_preprocessor.stem_and_lemmatize()\n",
    "test_df = test_text_preprocessor.get_df()\n",
    "\n",
    "val_text_preprocessor = Text_Preprocessor(val_df)\n",
    "val_text_preprocessor.lower_case()\n",
    "val_text_preprocessor.remove_null()\n",
    "val_text_preprocessor.stem_and_lemmatize()\n",
    "val_df = val_text_preprocessor.get_df()\n",
    "\n",
    "train_df.to_csv('../data/facebook/train.csv')\n",
    "test_df.to_csv('../data/facebook/test.csv')\n",
    "val_df.to_csv('../data/facebook/val.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Preprocessing:\n",
    "    def __init__(self, df, dir_name):\n",
    "        self.df = df\n",
    "        self.dir_name = dir_name\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    \n",
    "    def resize_and_grayscale(self):\n",
    "        for id in tqdm(self.df['id']):\n",
    "            file_name = str(id) + '.png'\n",
    "            _image = Image.open(os.path.join('../data/facebook/img', self.dir_name, file_name))\n",
    "            _image = _image.convert('L')\n",
    "            _image = _image.resize((224, 224))\n",
    "            _image.save(os.path.join('../data/facebook/img', self.dir_name, file_name))\n",
    "            \n",
    "\n",
    "    def __rotate(self, id):\n",
    "        file_name = str(id) + '.png'\n",
    "        new_file_name = str(id) + \"_augmented.png\"\n",
    "        path = os.path.join('../data/facebook/img', self.dir_name, file_name)\n",
    "        _image = np.array(Image.open(path))\n",
    "        angle = tf.random.uniform([], minval=-60, maxval=60)\n",
    "        _image = tf.keras.preprocessing.image.random_rotation(_image, angle, row_axis=0, col_axis=1, channel_axis=2)\n",
    "        _image = Image.fromarray(_image)\n",
    "        _image.save(os.path.join('../data/facebook/img', self.dir_name, new_file_name))\n",
    "        text = self.df[self.df['id'] == id]['text']\n",
    "        new_id = new_file_name.strip('.png')\n",
    "        if 'label' in self.df.columns:\n",
    "            label = self.df[self.df['id'] == id]['label']\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text, label]\n",
    "        else:\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text]\n",
    "\n",
    "    def __gaussian_noise(self, id):\n",
    "        file_name = str(id) + '.png'\n",
    "        new_file_name = str(id) + \"_augmented.png\"\n",
    "        path = os.path.join('../data/facebook/img', self.dir_name, file_name)\n",
    "        _image = np.array(Image.open(path))\n",
    "        noise = tf.random.normal(shape=tf.shape(_image), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "        _image = tf.clip_by_value(_image + noise, 0, 1)\n",
    "        _image = np.array(_image)\n",
    "        _image = Image.fromarray(_image)\n",
    "        _image.save(os.path.join('../data/facebook/img/', self.dir_name, new_file_name))\n",
    "        text = self.df[self.df['id'] == id]['text']\n",
    "        new_id = new_file_name.strip('.png')\n",
    "        if 'label' in self.df.columns:\n",
    "            label = self.df[self.df['id'] == id]['label']\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text, label]\n",
    "        else:\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text]\n",
    "\n",
    "    def __blur(self, id):\n",
    "        file_name = str(id) + '.png'\n",
    "        new_file_name = str(id) + \"_augmented.png\"\n",
    "        path = os.path.join('../data/facebook/img', self.dir_name, file_name)\n",
    "        _image = np.array(Image.open(path))\n",
    "        kernel_size = tf.random.uniform([], minval=3, maxval=7, dtype=tf.int32)\n",
    "        _image = tf.expand_dims(cv2.GaussianBlur(_image.np(), (kernel_size, kernel_size), 0), axis=2)\n",
    "        _image = Image.fromarray(_image)\n",
    "        _image.save(os.path.join('../data/facebook/img/', self.dir_name, new_file_name))\n",
    "        text = self.df[self.df['id'] == id]['text']\n",
    "        new_id = new_file_name.strip('.png')\n",
    "        if 'label' in self.df.columns:\n",
    "            label = self.df[self.df['id'] == id]['label']\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text, label]\n",
    "        else:\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text]\n",
    "\n",
    "    def augmentation(self):\n",
    "        for id in tqdm(self.df['id']):\n",
    "            # # Select a random augmentation\n",
    "            # augmentations = [self.__rotate, self.__gaussian_noise, self.__blur]\n",
    "            # selected_augmentation = np.random.choice(augmentations)\n",
    "\n",
    "            # # Apply the selected augmentation\n",
    "            # selected_augmentation(id)\n",
    "\n",
    "            self.__gaussian_noise(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/531 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/PIL/Image.py:3080\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3080\u001b[0m     mode, rawmode \u001b[39m=\u001b[39m _fromarray_typemap[typekey]\n\u001b[1;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<f4')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 79\u001b[0m, in \u001b[0;36mImage_Preprocessing.augmentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maugmentation\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     71\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     72\u001b[0m         \u001b[39m# # Select a random augmentation\u001b[39;00m\n\u001b[1;32m     73\u001b[0m         \u001b[39m# augmentations = [self.__rotate, self.__gaussian_noise, self.__blur]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[39m# # Apply the selected augmentation\u001b[39;00m\n\u001b[1;32m     77\u001b[0m         \u001b[39m# selected_augmentation(id)\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__gaussian_noise(\u001b[39mid\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mImage_Preprocessing.__gaussian_noise\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     41\u001b[0m _image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mclip_by_value(_image \u001b[39m+\u001b[39m noise, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m)\n\u001b[1;32m     42\u001b[0m _image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(_image)\n\u001b[0;32m---> 43\u001b[0m _image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(_image)\n\u001b[1;32m     44\u001b[0m _image\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m../data/facebook/img/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir_name, new_file_name))\n\u001b[1;32m     45\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mid\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/PIL/Image.py:3083\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3082\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot handle this data type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m typekey\n\u001b[0;32m-> 3083\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     rawmode \u001b[39m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f4"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_img_preprocessor = Image_Preprocessing(val_df, \"val\")\n",
    "train_img_preprocessor.augmentation()\n",
    "train_img_preprocessor.resize_and_grayscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HMC",
   "language": "python",
   "name": "hmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
