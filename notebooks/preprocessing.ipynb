{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT\n",
    "* remove_null\n",
    "* lower case\n",
    "* stem and lemmatize\n",
    "\n",
    "## IMAGE\n",
    "* resize all and save (grayscale)\n",
    "* augmentation using GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sameep/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2023-03-16 17:21:20.168360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 17:21:20.334065: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-16 17:21:20.337022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 17:21:20.337038: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-16 17:21:21.111368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 17:21:21.111517: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 17:21:21.111527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import cv2\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16395</td>\n",
       "      <td>handjob sold seper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37405</td>\n",
       "      <td>introduc fidget spinner for woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94180</td>\n",
       "      <td>happi pride month let' go beat up lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54321</td>\n",
       "      <td>laugh in [major of u. crime rate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97015</td>\n",
       "      <td>find out those 72 virgins.. are goat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                       text\n",
       "0  16395                         handjob sold seper\n",
       "1  37405          introduc fidget spinner for woman\n",
       "2  94180  happi pride month let' go beat up lesbian\n",
       "3  54321          laugh in [major of u. crime rate]\n",
       "4  97015       find out those 72 virgins.. are goat"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/facebook/train.csv')\n",
    "train_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "test_df = pd.read_csv('../data/facebook/test.csv')\n",
    "test_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "val_df = pd.read_csv('../data/facebook/val.csv')\n",
    "val_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Preprocessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    \n",
    "    def lower_case(self):\n",
    "        self.df['text'] = self.df['text'].apply(str.lower)\n",
    "\n",
    "    def remove_null(self):\n",
    "        for col in self.df.columns:\n",
    "            if(self.df[col].isnull().sum() > 0):\n",
    "                self.df.dropna(inplace = True)\n",
    "\n",
    "    def stem_and_lemmatize(self):\n",
    "        cleaned_text = []\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        for index in tqdm(range(self.df.shape[0])):\n",
    "            text = self.df['text'].iloc[index]\n",
    "\n",
    "            word_tokens = text.split()\n",
    "\n",
    "            for count, word in enumerate(word_tokens):\n",
    "                temp = lemmatizer.lemmatize(word)\n",
    "                word_tokens[count] = ps.stem(temp)\n",
    "\n",
    "            filtered_sentence = \" \".join(word_tokens).strip()\n",
    "            cleaned_text.append(filtered_sentence)\n",
    "        \n",
    "        self.df['text'] = np.array(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8500/8500 [00:03<00:00, 2199.31it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3562.92it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 4264.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>it their charact not their color that matter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>don't be afraid to love again everyon is not l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>put bow on your pet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>i love everyth and everybody! except for squir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>everybodi love chocol chip cookies, even hitler</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label\n",
       "0  42953       it their charact not their color that matter      0\n",
       "1  23058  don't be afraid to love again everyon is not l...      0\n",
       "2  13894                                put bow on your pet      0\n",
       "3  37408  i love everyth and everybody! except for squir...      0\n",
       "4  82403    everybodi love chocol chip cookies, even hitler      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_preprocessor = Text_Preprocessor(train_df)\n",
    "train_text_preprocessor.lower_case()\n",
    "train_text_preprocessor.remove_null()\n",
    "train_text_preprocessor.stem_and_lemmatize()\n",
    "train_df = train_text_preprocessor.get_df()\n",
    "\n",
    "test_text_preprocessor = Text_Preprocessor(test_df)\n",
    "test_text_preprocessor.lower_case()\n",
    "test_text_preprocessor.remove_null()\n",
    "test_text_preprocessor.stem_and_lemmatize()\n",
    "test_df = test_text_preprocessor.get_df()\n",
    "\n",
    "val_text_preprocessor = Text_Preprocessor(val_df)\n",
    "val_text_preprocessor.lower_case()\n",
    "val_text_preprocessor.remove_null()\n",
    "val_text_preprocessor.stem_and_lemmatize()\n",
    "val_df = val_text_preprocessor.get_df()\n",
    "\n",
    "train_df.to_csv('../data/facebook/train.csv')\n",
    "test_df.to_csv('../data/facebook/test.csv')\n",
    "val_df.to_csv('../data/facebook/val.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Preprocessing:\n",
    "    def __init__(self, df, dir_name):\n",
    "        self.df = df\n",
    "        self.dir_name = dir_name\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    \n",
    "    def resize_and_grayscale(self):\n",
    "        for id in tqdm(self.df['id']):\n",
    "            file_name = str(id) + '.png'\n",
    "            _image = Image.open(os.path.join('../data/facebook/img', self.dir_name, file_name))\n",
    "            _image = _image.convert('L')\n",
    "            _image = _image.resize((224, 224))\n",
    "            _image.save(os.path.join('../data/facebook/img', self.dir_name, file_name))\n",
    "            \n",
    "\n",
    "    def __rotate(self, id):\n",
    "        file_name = str(id) + '.png'\n",
    "        new_file_name = str(id) + \"_augmented.png\"\n",
    "        path = os.path.join('../data/facebook/img', self.dir_name, file_name)\n",
    "        _image = np.array(Image.open(path))\n",
    "        angle = tf.random.uniform([], minval=-60, maxval=60)\n",
    "        _image = tf.keras.preprocessing.image.random_rotation(_image, angle, row_axis=0, col_axis=1, channel_axis=2)\n",
    "        _image = Image.fromarray(_image)\n",
    "        _image.save(os.path.join('../data/facebook/img', self.dir_name, new_file_name))\n",
    "        text = self.df[self.df['id'] == id]['text']\n",
    "        new_id = new_file_name.strip('.png')\n",
    "        if 'label' in self.df.columns:\n",
    "            label = self.df[self.df['id'] == id]['label']\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text, label]\n",
    "        else:\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text]\n",
    "\n",
    "    def __gaussian_noise(self, id):\n",
    "        file_name = str(id) + '.png'\n",
    "        new_file_name = str(id) + \"_augmented.png\"\n",
    "        path = os.path.join('../data/facebook/img', self.dir_name, file_name)\n",
    "        _image = np.array(Image.open(path))\n",
    "        noise = tf.random.normal(shape=tf.shape(_image), mean=0, stddev=50, dtype=tf.float32)\n",
    "        _image = tf.clip_by_value(_image + noise, 0, 1)\n",
    "        _image = _image*255\n",
    "        _image = np.array(_image, dtype=np.uint8)\n",
    "        _image = Image.fromarray(_image)\n",
    "        _image.save(os.path.join('../data/facebook/img/', self.dir_name, new_file_name))\n",
    "        text = self.df[self.df['id'] == id]['text']\n",
    "        new_id = new_file_name.strip('.png')\n",
    "        if 'label' in self.df.columns:\n",
    "            label = self.df[self.df['id'] == id]['label']\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text, label]\n",
    "        else:\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text]\n",
    "\n",
    "    def __blur(self, id):\n",
    "        file_name = str(id) + '.png'\n",
    "        new_file_name = str(id) + \"_augmented.png\"\n",
    "        path = os.path.join('../data/facebook/img', self.dir_name, file_name)\n",
    "        _image = np.array(Image.open(path))\n",
    "        kernel_size = tf.random.uniform([1], minval=3, maxval=7, dtype=tf.int32)\n",
    "        _image = tf.expand_dims(cv2.GaussianBlur(np.array(_image), (np.array(kernel_size)[0], np.array(kernel_size)[0]), 0), axis=2)\n",
    "        _image = Image.fromarray(_image)\n",
    "        _image.save(os.path.join('../data/facebook/img/', self.dir_name, new_file_name))\n",
    "        text = self.df[self.df['id'] == id]['text']\n",
    "        new_id = new_file_name.strip('.png')\n",
    "        if 'label' in self.df.columns:\n",
    "            label = self.df[self.df['id'] == id]['label']\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text, label]\n",
    "        else:\n",
    "            self.df.loc[len(self.df.index)] = [new_id, text]\n",
    "\n",
    "    def augmentation(self):\n",
    "        for id in tqdm(self.df['id']):\n",
    "            # # Select a random augmentation\n",
    "            # augmentations = [self.__rotate, self.__gaussian_noise, self.__blur]\n",
    "            # selected_augmentation = np.random.choice(augmentations)\n",
    "\n",
    "            # # Apply the selected augmentation\n",
    "            # selected_augmentation(id)\n",
    "\n",
    "            self.__blur(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2023-03-16 17:21:26.613157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sameep/Extra_Projects/Human_Pose_Estimation/venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-03-16 17:21:26.613247: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-16 17:21:26.613294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sameep-Inspiron-5593): /proc/driver/nvidia/version does not exist\n",
      "2023-03-16 17:21:26.613998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/smooth.dispatch.cpp:293: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'createGaussianKernels'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 80\u001b[0m, in \u001b[0;36mImage_Preprocessing.augmentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maugmentation\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     73\u001b[0m         \u001b[39m# # Select a random augmentation\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         \u001b[39m# augmentations = [self.__rotate, self.__gaussian_noise, self.__blur]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[39m# # Apply the selected augmentation\u001b[39;00m\n\u001b[1;32m     78\u001b[0m         \u001b[39m# selected_augmentation(id)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__blur(\u001b[39mid\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m, in \u001b[0;36mImage_Preprocessing.__blur\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     58\u001b[0m _image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(path))\n\u001b[1;32m     59\u001b[0m kernel_size \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform([\u001b[39m1\u001b[39m], minval\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, maxval\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32)\n\u001b[0;32m---> 60\u001b[0m _image \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(cv2\u001b[39m.\u001b[39;49mGaussianBlur(np\u001b[39m.\u001b[39;49marray(_image), (np\u001b[39m.\u001b[39;49marray(kernel_size)[\u001b[39m0\u001b[39;49m], np\u001b[39m.\u001b[39;49marray(kernel_size)[\u001b[39m0\u001b[39;49m]), \u001b[39m0\u001b[39;49m), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     61\u001b[0m _image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(_image)\n\u001b[1;32m     62\u001b[0m _image\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m../data/facebook/img/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir_name, new_file_name))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/smooth.dispatch.cpp:293: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'createGaussianKernels'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_img_preprocessor = Image_Preprocessing(val_df, \"val\")\n",
    "train_img_preprocessor.augmentation()\n",
    "train_img_preprocessor.resize_and_grayscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HMC",
   "language": "python",
   "name": "hmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
